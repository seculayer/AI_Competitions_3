{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport warnings\nfrom tqdm import tqdm\nfrom datetime import datetime\nimport json\nfrom sklearn.preprocessing import LabelEncoder\nwarnings.filterwarnings(\"ignore\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-06-28T07:28:48.07882Z","iopub.execute_input":"2022-06-28T07:28:48.079176Z","iopub.status.idle":"2022-06-28T07:28:48.086948Z","shell.execute_reply.started":"2022-06-28T07:28:48.079097Z","shell.execute_reply":"2022-06-28T07:28:48.084193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"external datasets\n1. **TMDB Competition Additional Features:** This dataset contain rating & number of votes of a movie.\n2. **TMDB Competition Additional Training Data:** This dataset contain around 2,000 additional rows, which I am using for training the data. ","metadata":{"_uuid":"79df05d97ee146e5c540633147be37915b8fdda2"}},{"cell_type":"code","source":"from collections import defaultdict\n\ndef prepare(df):\n    global json_cols\n    global train_dict\n    \n    # release_year\n    df[['release_month','release_day','release_year']]=df['release_date'].str.split('/',expand=True).replace(np.nan, 0).astype(int)\n    # TMDB Box Office Prediction Competition launch year : 2019\n    df.loc[(df['release_year'] <= 19) & (df['release_year'] < 100), \"release_year\"] += 2000\n    df.loc[(df['release_year'] > 19)  & (df['release_year'] < 100), \"release_year\"] += 1900\n    \n    releaseDate = pd.to_datetime(df['release_date']) \n    df['release_dayofweek'] = releaseDate.dt.dayofweek \n    df['release_quarter'] = releaseDate.dt.quarter     \n    \n    # To handle missing value of rating, totalvotes, \n    # consider mean value of rating group by 'release year', 'original language' \n    rating_na = df.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\n    df[df.rating.isna()]['rating'] = df.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n    vote_count_na = df.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\n    df[df.totalVotes.isna()]['totalVotes'] = df.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\n    \n    df['budget'] = np.log1p(df['budget']) \n    \n    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n    df['_collection_name'] = df['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\n    le = LabelEncoder()\n    le.fit(list(df['_collection_name'].fillna('')))\n    df['_collection_name'] = le.transform(df['_collection_name'].fillna('').astype(str))\n    df['_num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n    df['_num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n    \n    # Don't need to consider all values -> Binarization\n    df['has_homepage'] = 1\n    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0\n    \n    df['isbelongs_to_collectionNA'] = 0\n    df.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 1\n    \n    df['isTaglineNA'] = 0\n    df.loc[df['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n\n    df['isOriginalLanguageEng'] = 0 \n    df.loc[ df['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n    \n    df['isTitleDifferent'] = 1\n    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n\n    df['isMovieReleased'] = 1\n    df.loc[ df['status'] != \"Released\" ,\"isMovieReleased\"] = 0 \n\n    # get collection id\n    df['collection_id'] = df['belongs_to_collection'].apply(lambda x : np.nan if len(x)==0 else x[0]['id'])\n\n    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n    \n    # Handling categorical features -> dict type\n    for col in ['genres', 'production_countries', 'spoken_languages', 'production_companies'] :\n        df[col] = df[col].map(lambda x: sorted(list(set([n if n in train_dict[col] else col+'_etc' for n in [d['name'] for d in x]])))).map(lambda x: ','.join(map(str, x)))\n        print(df[col])\n        temp = df[col].str.get_dummies(sep=',')\n        df = pd.concat([df, temp], axis=1, sort=False)\n    df.drop(['genres_etc'], axis = 1, inplace = True)\n    \n    df = df.drop(['id', 'revenue','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'collection_id'\n    ],axis=1)\n    \n    df.fillna(value=0.0, inplace = True) \n\n    return df\n\ndef get_dictionary(s):\n    \"\"\"\n    get dict string -> dict\n    \"\"\"\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d\n\ndef get_json_dict(df):\n    global json_cols\n    result = dict()\n    for e_col in json_cols:\n        d = defaultdict(int)\n        rows = df[e_col].values\n        for row in rows:\n            if row is None: \n                continue\n            for i in row:\n                d[i['name']] += 1\n        result[e_col] = d\n    return result\n","metadata":{"_uuid":"85e47d6d91209014e7a3e897e4290793054bf2fb","execution":{"iopub.status.busy":"2022-06-28T07:28:55.458088Z","iopub.execute_input":"2022-06-28T07:28:55.458593Z","iopub.status.idle":"2022-06-28T07:28:55.483445Z","shell.execute_reply.started":"2022-06-28T07:28:55.458517Z","shell.execute_reply":"2022-06-28T07:28:55.482113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## fillna revenue, budget ","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\n\n# Clean train data(revenue, budget)\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\ntrain.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000\n\n\n\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\n\n# Clean test data(budget)\ntest.loc[test['id'] == 6733,'budget'] = 5000000\ntest.loc[test['id'] == 3889,'budget'] = 15000000\ntest.loc[test['id'] == 6683,'budget'] = 50000000\ntest.loc[test['id'] == 5704,'budget'] = 4300000\ntest.loc[test['id'] == 6109,'budget'] = 281756\ntest.loc[test['id'] == 7242,'budget'] = 10000000\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\ntest.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30\ntest['revenue'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2022-06-28T07:28:56.063115Z","iopub.execute_input":"2022-06-28T07:28:56.06364Z","iopub.status.idle":"2022-06-28T07:28:57.382537Z","shell.execute_reply.started":"2022-06-28T07:28:56.063593Z","shell.execute_reply":"2022-06-28T07:28:57.38106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# on train set of competition, imdb_id exist -> we can use another public dataset which have imdb_id feature\ntrain = pd.merge(train, pd.read_csv('../input/tmdb-competition-additional-features/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\ntest = pd.merge(test, pd.read_csv('../input/tmdb-competition-additional-features/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n\nadditionalTrainData = pd.read_csv('../input/tmdb-box-office-prediction-more-training-data/additionalTrainData.csv')\nadditionalTrainData['release_date'] = additionalTrainData['release_date'].astype('str')\nadditionalTrainData['release_date'] = additionalTrainData['release_date'].str.replace('-', '/')\nprint(train.head())\nprint(train.info())\nprint(additionalTrainData.head())\nprint(additionalTrainData.info())\ntrain = pd.concat([train, additionalTrainData])\nprint(train.head())\nprint(train.info())\n\nprint(train.columns)\nprint(train.shape)\n# revenue -> target variable -> only exist train data -> not in prepare data(train + test preprocessing)\ntrain['revenue'] = np.log1p(train['revenue'])\ny = train['revenue'].values\n\njson_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\nfor col in tqdm(json_cols + ['belongs_to_collection']) :\n    train[col] = train[col].apply(lambda x : get_dictionary(x))\n    test[col] = test[col].apply(lambda x : get_dictionary(x))\n\ntrain_dict = get_json_dict(train)\ntest_dict = get_json_dict(test)\n\n\nfor col in json_cols:    \n    remove = []\n    train_id = set(list(train_dict[col].keys()))\n    test_id = set(list(test_dict[col].keys()))   \n    \n    remove += list(train_id - test_id) + list(test_id - train_id)\n    for i in train_id.union(test_id) - set(remove):\n        if train_dict[col][i] < 10 or i == '':\n            remove += [i]\n            \n    for i in remove:\n        if i in train_dict[col]:\n            del train_dict[col][i]\n        if i in test_dict[col]:\n            del test_dict[col][i]\n            \nall_data = prepare(pd.concat([train, test]).reset_index(drop = True))\ntrain = all_data.loc[:train.shape[0] - 1,:]\ntest = all_data.loc[train.shape[0]:,:] \nprint(train.head())\nprint(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-06-28T07:28:58.374325Z","iopub.execute_input":"2022-06-28T07:28:58.374684Z","iopub.status.idle":"2022-06-28T07:29:21.41013Z","shell.execute_reply.started":"2022-06-28T07:28:58.374613Z","shell.execute_reply":"2022-06-28T07:29:21.409341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nrandom_seed = 2019\nk = 10\nfold = list(KFold(k, shuffle = True, random_state = random_seed).split(train))\nnp.random.seed(random_seed)","metadata":{"_uuid":"66dec4758c797f9bb30ab293bae9ddcd3ebeb496","execution":{"iopub.status.busy":"2022-05-19T05:52:28.52397Z","iopub.execute_input":"2022-05-19T05:52:28.525366Z","iopub.status.idle":"2022-05-19T05:52:28.536826Z","shell.execute_reply.started":"2022-05-19T05:52:28.525286Z","shell.execute_reply":"2022-05-19T05:52:28.535693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\n\ndef xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n    params = {'objective': 'reg:linear', \n              'eta': 0.01, \n              'max_depth': 6, \n              'subsample': 0.6, \n              'colsample_bytree': 0.7,  \n              'eval_metric': 'rmse', \n              'seed': random_seed, \n              'silent': True,\n    }\n    \n    record = dict()\n    model = xgb.train(params\n                      , xgb.DMatrix(trn_x, trn_y)\n                      , 100000\n                      , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n                      , verbose_eval=verbose\n                      , early_stopping_rounds=500\n                      , callbacks = [xgb.callback.record_evaluation(record)])\n    best_idx = np.argmin(np.array(record['valid']['rmse']))\n\n    val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n\n    return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}","metadata":{"_uuid":"a974284e8e9a7491353eb8a2b5ba72bb7034ae59","execution":{"iopub.status.busy":"2022-05-19T05:52:28.908448Z","iopub.execute_input":"2022-05-19T05:52:28.908796Z","iopub.status.idle":"2022-05-19T05:52:28.920827Z","shell.execute_reply.started":"2022-05-19T05:52:28.908746Z","shell.execute_reply":"2022-05-19T05:52:28.919916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training using LightGBM","metadata":{"_uuid":"4594293787a7cd16d5061e662c48a0eecaf6e1c8"}},{"cell_type":"code","source":"import lightgbm as lgb\n\ndef lgb_model(trn_x, trn_y, val_x, val_y, test, verbose):\n    params = {'objective':'regression',\n         'num_leaves' : 30,\n         'max_depth' : 9,\n         'learning_rate': 0.004,\n         'feature_fraction':0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         'lambda_l1': 0.2,\n         \"bagging_seed\": random_seed,\n         \"metric\": 'rmse',\n         \"random_state\" : random_seed,\n         \"verbosity\": -1}\n\n    record = dict()\n    model = lgb.train(params\n                      , lgb.Dataset(trn_x, trn_y)\n                      , num_boost_round = 100000\n                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n                      , verbose_eval = verbose\n                      , early_stopping_rounds = 500\n                      , callbacks = [lgb.record_evaluation(record)]\n                     )\n    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\n    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n    test_pred = model.predict(test, num_iteration = model.best_iteration)\n    \n    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}","metadata":{"_uuid":"a604e67f6d7c4894bf15509efa7f60dd7ef691e0","execution":{"iopub.status.busy":"2022-05-19T05:52:29.698548Z","iopub.execute_input":"2022-05-19T05:52:29.699259Z","iopub.status.idle":"2022-05-19T05:52:29.711819Z","shell.execute_reply.started":"2022-05-19T05:52:29.699198Z","shell.execute_reply":"2022-05-19T05:52:29.710649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training with CatBoost","metadata":{"_uuid":"f98d631fc76e05bc39a0c83564edc1c9b485e250"}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ndef cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n    model = CatBoostRegressor(iterations=100000,\n                                 learning_rate=0.004,\n                                 depth=5,\n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.8,\n                                 random_seed = random_seed,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=200\n                                )\n    model.fit(trn_x, trn_y,\n                 eval_set=(val_x, val_y),\n                 use_best_model=True,\n                 verbose=False)\n    \n    val_pred = model.predict(val_x)\n    test_pred = model.predict(test)\n    \n    return {'val':val_pred, \n            'test':test_pred, \n            'error':model.get_best_score()['validation_0']['RMSE']}","metadata":{"_uuid":"3846a12f6a76215516cbf4fd895423538a55709b","execution":{"iopub.status.busy":"2022-05-19T05:52:30.628931Z","iopub.execute_input":"2022-05-19T05:52:30.629439Z","iopub.status.idle":"2022-05-19T05:52:30.640353Z","shell.execute_reply.started":"2022-05-19T05:52:30.629366Z","shell.execute_reply":"2022-05-19T05:52:30.638926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result_dict = dict()\nval_pred = np.zeros(train.shape[0])\ntest_pred = np.zeros(test.shape[0])\nfinal_err = 0\nverbose = False\n\n\nfor i, (trn, val) in enumerate(fold) :\n    print(i+1, \"fold.    RMSE\")\n    \n    trn_x = train.loc[trn, :]\n    trn_y = y[trn]\n    val_x = train.loc[val, :]\n    val_y = y[val]\n    \n    fold_val_pred = []\n    fold_test_pred = []\n    fold_err = []\n    \n    # xgboost\n    #     start = datetime.now()\n    #     result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    #     #fold_val_pred.append(result['val'] / 3)\n    #     fold_val_pred.append(result['val'])\n\n    #     fold_test_pred.append(result['test'])\n    #     fold_err.append(result['error'])\n    #     print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n\n    \n    # lightgbm\n    start = datetime.now()\n    result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    # fold_val_pred.append(result['val'] / 3)\n    fold_val_pred.append(result['val'])\n\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n    \n    \n    # catboost model\n    start = datetime.now()\n    result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n    # fold_val_pred.append(result['val'] / 3)\n    fold_val_pred.append(result['val'])\n\n    fold_test_pred.append(result['test'])\n    fold_err.append(result['error'])\n    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n    \n    \n    # mix result of multiple models\n    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0) / k    \n    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / k\n    final_err += (sum(fold_err) / len(fold_err)) / k\n    \n    print(\"---------------------------\")\n    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n    print('')\n    \nprint(\"final avg   err.\", final_err)\nprint(\"final blend err.\", np.sqrt(np.mean((val_pred - y)**2)))","metadata":{"_uuid":"fa1701284accc13028d70ca7887d0d13e9e0f3c3","execution":{"iopub.status.busy":"2022-05-19T05:52:45.079274Z","iopub.execute_input":"2022-05-19T05:52:45.079675Z","iopub.status.idle":"2022-05-19T06:20:25.232434Z","shell.execute_reply.started":"2022-05-19T05:52:45.079606Z","shell.execute_reply":"2022-05-19T06:20:25.231293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission","metadata":{"_uuid":"f52ef39705248f09318e9fa416f32ade673e4b97"}},{"cell_type":"code","source":"sub = pd.read_csv('../input/tmdb-box-office-prediction/sample_submission.csv')\ndf_sub = pd.DataFrame()\ndf_sub['id'] = sub['id']\n# In train set, log(revenue) -> np.expm1(test_pred) -> e ** ln(x) = x\ndf_sub['revenue'] = np.expm1(test_pred)\ndf_sub.to_csv(\"submission.csv\", index=False)","metadata":{"_uuid":"1ee63a69c68d3fe2948682c3215692f36113e2bf","execution":{"iopub.status.busy":"2022-05-19T06:20:25.234579Z","iopub.execute_input":"2022-05-19T06:20:25.234858Z","iopub.status.idle":"2022-05-19T06:20:25.293968Z","shell.execute_reply.started":"2022-05-19T06:20:25.23481Z","shell.execute_reply":"2022-05-19T06:20:25.292998Z"},"trusted":true},"execution_count":null,"outputs":[]}]}