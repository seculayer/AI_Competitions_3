{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport datetime as dt\nimport os\nfrom sklearn.model_selection import train_test_split\n\nimport lightgbm as lgb\nimport gc\n\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-27T05:13:28.881976Z","iopub.execute_input":"2022-06-27T05:13:28.882455Z","iopub.status.idle":"2022-06-27T05:13:30.388699Z","shell.execute_reply.started":"2022-06-27T05:13:28.882365Z","shell.execute_reply":"2022-06-27T05:13:30.387541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_PATH = '../input/new-york-city-taxi-fare-prediction/train.csv'\nTEST_PATH = '../input/new-york-city-taxi-fare-prediction/test.csv'\nSAMPLE_SUBMISSION_PATH = '../input/new-york-city-taxi-fare-prediction/sample_submission.csv'\ncols = ['fare_amount', 'pickup_datetime', 'pickup_longitude', 'pickup_latitude',\n        'dropoff_longitude', 'dropoff_latitude', 'passenger_count']\nchunksize = 5e6","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:13:30.390345Z","iopub.execute_input":"2022-06-27T05:13:30.390786Z","iopub.status.idle":"2022-06-27T05:13:30.395704Z","shell.execute_reply.started":"2022-06-27T05:13:30.39075Z","shell.execute_reply":"2022-06-27T05:13:30.394583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reduce mem usage -> Train data","metadata":{}},{"cell_type":"code","source":"df_list = [] # list to hold the batch dataframe\n\nfor df_chunk in tqdm(pd.read_csv(TRAIN_PATH, usecols=cols, chunksize=chunksize, dtype={'passenger_count':np.int8})):\n    df_chunk['pickup_datetime'] = df_chunk['pickup_datetime'].str.slice(0, 16)\n    df_chunk['pickup_datetime'] = pd.to_datetime(df_chunk['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n    df_list.append(df_chunk) \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:13:32.395915Z","iopub.execute_input":"2022-06-27T05:13:32.396733Z","iopub.status.idle":"2022-06-27T05:16:06.105612Z","shell.execute_reply.started":"2022-06-27T05:13:32.396694Z","shell.execute_reply":"2022-06-27T05:16:06.104192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge all dataframes into one dataframe\ntrain_df = pd.concat(df_list)\nprint(train_df.shape)\ntrain_df = train_df[:20000000]\n# Delete the dataframe list to release memory\ndel df_list","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:16:06.108856Z","iopub.execute_input":"2022-06-27T05:16:06.109764Z","iopub.status.idle":"2022-06-27T05:16:09.894255Z","shell.execute_reply.started":"2022-06-27T05:16:06.109717Z","shell.execute_reply":"2022-06-27T05:16:09.893408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_haversine(pickup_lat, pickup_lon, dropoff_lat, dropoff_lon):\n    \"\"\"\n    Return distance along great radius between pickup and dropoff coordinates.\n    \"\"\"\n    #Define earth radius (km)\n    R_earth = 6371\n    \n    #Convert degrees to radians\n    pickup_lat, pickup_lon, dropoff_lat, dropoff_lon = map(np.radians,\n                                                             [pickup_lat, pickup_lon, \n                                                              dropoff_lat, dropoff_lon])\n    #Compute distances along lat, lon dimensions\n    dlat = dropoff_lat - pickup_lat\n    dlon = dropoff_lon - pickup_lon\n    \n    #Compute haversine distance\n    a = np.sin(dlat/2.0)**2 + np.cos(pickup_lat) * np.cos(dropoff_lat) * np.sin(dlon/2.0)**2\n    \n    return 2 * R_earth * np.arcsin(np.sqrt(a))","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:16:09.895344Z","iopub.execute_input":"2022-06-27T05:16:09.895629Z","iopub.status.idle":"2022-06-27T05:16:09.902403Z","shell.execute_reply.started":"2022-06-27T05:16:09.895605Z","shell.execute_reply":"2022-06-27T05:16:09.901533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(df, bbox, is_train=True):\n    \"\"\"\n    data preprocessing both train set and test set\n    \"\"\"\n    df.dropna(inplace=True)\n    \n    # 2. longitude & latitude    \n    \n    # There are some strange values that can think 'longitude, latitude have to swap'\n    if is_train:\n        # bbox\n        df = df[(df.pickup_longitude >= bbox[0]) & (df.pickup_longitude <= bbox[1]) &\n                    (df.pickup_latitude >= bbox[2]) & (df.pickup_latitude <= bbox[3]) & \n                    (df.dropoff_longitude >= bbox[0]) & (df.dropoff_longitude <= bbox[1]) & \n                    (df.dropoff_latitude >= bbox[2]) & (df.dropoff_latitude <= bbox[3])]\n\n        # 3. passenger\n        # NYC Taxi : 1 ~ 4, YelloRide : 1 ~ 7, Uber : 1 ~ 7\n        # In test set, maximum value of passenger_count == 6 -> passenger_count 7 : 13 rows in train set-> drop\n        df = df[(df.passenger_count > 0) & (df.passenger_count < 7)]\n    \n    # 4. datetime\n    df['hour'] = df.pickup_datetime.dt.hour.astype(np.int8)\n    df['day'] = df.pickup_datetime.dt.day.astype(np.int8)\n    df['month'] = df.pickup_datetime.dt.month.astype(np.int8)\n    df['weekday'] = df.pickup_datetime.dt.weekday.astype(np.int8)\n    df['year'] = df.pickup_datetime.dt.year.astype(np.int16)\n\n    df.drop(columns=['pickup_datetime'], inplace=True)   \n    df.reset_index(inplace=True)\n    \n    gc.collect()\n    \n    # 5. Haversine    \n    df['haversine'] = calculate_haversine(df.pickup_latitude, df.pickup_longitude, df.dropoff_latitude, df.dropoff_longitude).astype(np.float16)\n    \n    return df\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:16:09.904276Z","iopub.execute_input":"2022-06-27T05:16:09.905438Z","iopub.status.idle":"2022-06-27T05:16:09.919677Z","shell.execute_reply.started":"2022-06-27T05:16:09.905394Z","shell.execute_reply":"2022-06-27T05:16:09.918625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data cleaning, make haversine distance column","metadata":{}},{"cell_type":"code","source":"#tqdm.pandas()\n\ncols_test = ['pickup_datetime', 'pickup_longitude', 'pickup_latitude',\n        'dropoff_longitude', 'dropoff_latitude', 'passenger_count']\ntest = pd.read_csv(TEST_PATH, usecols=cols_test,dtype={'passenger_count':np.int8})\n\ntest['pickup_datetime'] = test['pickup_datetime'].str.slice(0, 16)\ntest['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'], utc=True, format='%Y-%m-%d %H:%M')\n\nbox = (min(test.pickup_longitude.min(), test.dropoff_longitude.min()),\n        max(test.pickup_longitude.max(), test.dropoff_longitude.max()),\n        min(test.pickup_latitude.min(), test.dropoff_latitude.min()),\n        max(test.pickup_latitude.max(), test.dropoff_latitude.max())\n        )\n\ntest = preprocessing(test, box, False)\ntest.drop(columns=['index'], inplace=True)\n\n\n# 1. fare -> initial charge of NYC taxi : 2.5\ntrain_df = train_df[(train_df.fare_amount >= 2.5) & (train_df.fare_amount < 100)]\ntrain = preprocessing(train_df, box)\nlen_train = train.shape[0]\n\ngc.collect()\ndel train_df\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:16:09.920837Z","iopub.execute_input":"2022-06-27T05:16:09.921296Z","iopub.status.idle":"2022-06-27T05:16:37.583882Z","shell.execute_reply.started":"2022-06-27T05:16:09.921266Z","shell.execute_reply":"2022-06-27T05:16:37.582703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Add Distance From Popular Landmarks","metadata":{}},{"cell_type":"code","source":"jfk_coord = (40.639722, -73.778889) # JFK airport\newr_coord = (40.6925, -74.168611)   # Newark Liberty International Airport\nlga_coord = (40.77725, -73.872611)  # LaGuardia airport\nmet_coord = (40.7794, -73.9632)     # MET museum\nwtc_coord = (40.7126, -74.0099)     # World Trade Center","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:20:47.248757Z","iopub.execute_input":"2022-06-27T01:20:47.249381Z","iopub.status.idle":"2022-06-27T01:20:47.257647Z","shell.execute_reply.started":"2022-06-27T01:20:47.249352Z","shell.execute_reply":"2022-06-27T01:20:47.257015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_landmark_dropoff_distance(df, landmark_name, landmark_lonlat):\n    lat, lon = landmark_lonlat\n    df[landmark_name + '_drop_distance'] = calculate_haversine(lat, lon, df.dropoff_latitude, df.dropoff_longitude).astype(np.float16)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:20:47.258648Z","iopub.execute_input":"2022-06-27T01:20:47.258931Z","iopub.status.idle":"2022-06-27T01:20:47.266848Z","shell.execute_reply.started":"2022-06-27T01:20:47.258904Z","shell.execute_reply":"2022-06-27T01:20:47.266267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for a_df in [train, test]:\n    for name, lonlat in [('jfk', jfk_coord), ('lga', lga_coord), ('ewr', ewr_coord), ('met', met_lonlat), ('wtc', wtc_lonlat)]:\n        add_landmark_dropoff_distance(a_df, name, lonlat)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:20:47.267868Z","iopub.execute_input":"2022-06-27T01:20:47.268286Z","iopub.status.idle":"2022-06-27T01:20:55.171975Z","shell.execute_reply.started":"2022-06-27T01:20:47.268258Z","shell.execute_reply":"2022-06-27T01:20:55.171085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lightgbm","metadata":{}},{"cell_type":"code","source":"# Lightgbm\n# # len_train = 54073228\n# # val_pred = np.zeros(len_train)\n# # test = pd.read_csv(AFTER_TEST_PATH)\n# test_pred = np.zeros(test.shape[0])\n# verbose = 1000\n# random_seed = 42\n# # chunksize = 13500000\n# test_size = 0.1 # -> 0.01 ?\n# # k = len_train // chunksize + 1\n# # k = len_train // chunksize\n# idx = 0","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:20:55.172786Z","iopub.execute_input":"2022-06-27T01:20:55.173002Z","iopub.status.idle":"2022-06-27T01:20:55.17605Z","shell.execute_reply.started":"2022-06-27T01:20:55.17298Z","shell.execute_reply":"2022-06-27T01:20:55.175612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lightgbm\n# verbose = 100\n# y = train['fare_amount']\n# train.drop(columns=['fare_amount', 'index'], inplace=True)\n# x_train, x_test, y_train, y_test = train_test_split(train, y, random_state=random_seed, test_size=test_size)\n    \n# # Hyperparameters Tuning in LightGBM docs\n\n# \n# params = {\n#         'objective': 'regression',\n#         \"boosting\" : \"gbdt\",\n#         'metric': 'rmse',\n#         'max_depth' : 7,\n#         #'min_data_in_leaf' : 20,\n#         'num_leaves':63,\n#         'learning_rate': 0.05,\n#         #'subsample': 0.8,\n#         #\"bagging_fraction\" : 0.7, \n#         #\"bagging_seed\" : 3,\n#         #\"bagging_freq\" : 5, \n#         #\"feature_fraction\" : 0.5, \n#         \"num_threads\" : 4,\n#         # 'max_bin' : 50,      # default 255, smaller -> deal with overfitting\n# #         'min_split_gain': 0.5,\n# #         'min_child_weight': 1,\n# #         'min_child_samples': 10,\n# #         'scale_pos_weight':1,\n# #         'zero_as_missing': True,\n#         'seed':random_seed,\n#         # 'num_rounds':50000,\n#         'device': 'gpu',\n#         'gpu_platform_id': 0,\n#         'gpu_device_id': 0,\n#         #'random_state':random_seed\n        \n# }\n# train_set = lgb.Dataset(x_train, label=y_train)\n# del x_train, y_train\n# valid_set = lgb.Dataset(x_test, label=y_test)\n# gc.collect()\n    \n# evals_result = {}\n# model = lgb.train(params\n#                         , train_set                     \n#                         , num_boost_round=3500\n#                         , valid_sets=[valid_set]\n#                         , verbose_eval=verbose                        \n#                         , early_stopping_rounds=125\n#                         , callbacks=[lgb.record_evaluation(evals_result), lgb.early_stopping(stopping_rounds=10)]\n#                         )\n\n# validation = model.predict(x_test, num_iteration=model.best_iteration)\n# del x_test\n# test_prediction = model.predict(test, num_iteration=model.best_iteration)\n# print(\"validation rmse\", \"{0:.5f}\".format(np.sqrt(np.mean((validation - y_test)**2))))\n# del y_test\n# # test_pred += test_prediction / k","metadata":{"execution":{"iopub.status.busy":"2022-06-27T01:20:55.17681Z","iopub.execute_input":"2022-06-27T01:20:55.17738Z","iopub.status.idle":"2022-06-27T01:20:55.186922Z","shell.execute_reply.started":"2022-06-27T01:20:55.177357Z","shell.execute_reply":"2022-06-27T01:20:55.186326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lightgbm\n# submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n# submission['fare_amount'] = test_prediction\n# submission['fare_amount'] = submission['fare_amount'].apply(lambda x:2.5 if x < 2.5 else x)\n# submission.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Xgboost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb \ndef XGBmodel(x_train,x_test,y_train,y_test,params):\n    matrix_train = xgb.DMatrix(x_train,label=y_train)\n    matrix_test = xgb.DMatrix(x_test,label=y_test)\n    model=xgb.train(params=params,\n                    dtrain=matrix_train,num_boost_round=5000, \n                    early_stopping_rounds=10,evals=[(matrix_test,'test')])\n    return model\n\nparams = {\n    # Parameters that we are going to tune.\n    'max_depth': 8, #Result of tuning with CV\n    'eta':.05, #Result of tuning with CV\n    'subsample': 1, #Result of tuning with CV\n    'colsample_bytree': 0.8, #Result of tuning with CV\n    # Other parameters\n    'objective':'reg:linear',\n    'eval_metric':'rmse',\n    'silent': 1\n}\nverbose = 1000\nrandom_seed = 42\ntest_size = 0.05\ny = train['fare_amount']\ntrain.drop(columns=['fare_amount', 'index'], inplace=True)\nx_train, x_test, y_train, y_test = train_test_split(train, y, random_state=random_seed, test_size=test_size)\n    \nmodel = XGBmodel(x_train,x_test,y_train,y_test,params)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T05:16:37.585113Z","iopub.execute_input":"2022-06-27T05:16:37.58544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(SAMPLE_SUBMISSION_PATH)\ntest_pred = model.predict(xgb.DMatrix(test), ntree_limit = model.best_ntree_limit)\nsubmission['fare_amount'] = test_pred\nsubmission['fare_amount'] = submission['fare_amount'].apply(lambda x:2.5 if x < 2.5 else x)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}