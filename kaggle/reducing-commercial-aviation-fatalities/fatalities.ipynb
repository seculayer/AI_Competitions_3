{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "016b563a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 1039.79 MB\n",
      "Memory usage after optimization is: 241.38 MB\n",
      "Decreased by 76.8%\n",
      "(4867421, 27)\n",
      "Index(['crew', 'experiment', 'time', 'seat', 'eeg_fp1', 'eeg_f7', 'eeg_f8',\n",
      "       'eeg_t4', 'eeg_t6', 'eeg_t5', 'eeg_t3', 'eeg_fp2', 'eeg_o1', 'eeg_p3',\n",
      "       'eeg_pz', 'eeg_f3', 'eeg_fz', 'eeg_f4', 'eeg_c4', 'eeg_p4', 'eeg_poz',\n",
      "       'eeg_c3', 'eeg_cz', 'eeg_o2', 'ecg', 'r', 'gsr'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.051422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6123\n",
      "[LightGBM] [Info] Number of data points in the train set: 3650565, number of used features: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/home/centos/anaconda3/envs/test_env/lib/python3.7/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Start training from score -0.552255\n",
      "[LightGBM] [Info] Start training from score -3.766158\n",
      "[LightGBM] [Info] Start training from score -1.044389\n",
      "[LightGBM] [Info] Start training from score -3.009791\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[100]\ttraining's multi_error: 0.0572889\tvalid_1's multi_error: 0.0838522\n",
      "[200]\ttraining's multi_error: 0.0408605\tvalid_1's multi_error: 0.0809833\n",
      "[300]\ttraining's multi_error: 0.0338331\tvalid_1's multi_error: 0.0813243\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's multi_error: 0.0410476\tvalid_1's multi_error: 0.0809208\n",
      "Memory usage of dataframe is 3837.77 MB\n",
      "Memory usage after optimization is: 942.31 MB\n",
      "Decreased by 75.4%\n",
      "Done test read\n",
      "                id         A         B         C         D\n",
      "0                0  0.951522  0.003137  0.039142  0.006199\n",
      "1                1  0.948906  0.004076  0.040003  0.007014\n",
      "2                2  0.952323  0.003158  0.038301  0.006218\n",
      "3                3  0.948901  0.004082  0.040003  0.007014\n",
      "4                4  0.952614  0.003075  0.038216  0.006095\n",
      "...            ...       ...       ...       ...       ...\n",
      "17965138  17965138  0.849880  0.005120  0.132821  0.012179\n",
      "17965139  17965139  0.915733  0.003918  0.070073  0.010277\n",
      "17965140  17965140  0.850593  0.005130  0.132074  0.012203\n",
      "17965141  17965141  0.915733  0.003918  0.070073  0.010277\n",
      "17965142  17965142  0.850599  0.005123  0.132075  0.012203\n",
      "\n",
      "[17965143 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#print(\"Read Done\")\n",
    "# Memory saving function credit to https://www.kaggle.com/gemartin/load-data-reduce-memory-usage\n",
    "\n",
    "''' Modify data type to reduce Memory Usage\n",
    "\n",
    "'''\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    " \n",
    "''' mapping y(event)'s data type: ABCE to 1234\n",
    "\n",
    "'''\n",
    "def featureModify(isTrain, numRows):\n",
    "    if isTrain:\n",
    "        df = pd.read_csv('./input/fatalities/train.csv',nrows=numRows) \n",
    "        df = reduce_mem_usage(df)\n",
    "        df['event'] = df['event'].map({\n",
    "            'A':0,\n",
    "            'B':1,\n",
    "            'C':2,\n",
    "            'D':3\n",
    "        })\n",
    "    else:\n",
    "        df = pd.read_csv('./input/fatalities/test.csv',nrows=numRows)\n",
    "        df = reduce_mem_usage(df)\n",
    "        \n",
    "    return df \n",
    "   \n",
    "train = featureModify(True, None)\n",
    "y = train['event']\n",
    "train = train.drop('event',axis=1)\n",
    "print(train.shape)\n",
    "print(train.columns)\n",
    "\n",
    "'''train test divide:: 0.75:0.25\n",
    "'''\n",
    "train, train_test, y, y_test = train_test_split(train, y, test_size=0.25, shuffle=False)\n",
    "train = lgb.Dataset(train, label=y.astype('int32'),categorical_feature=[1])\n",
    "train_test_df = train_test\n",
    "y_df = y\n",
    "del y\n",
    "gc.collect()\n",
    "train_test = lgb.Dataset(train_test, label=y_test.astype('int32'),categorical_feature=[1])\n",
    "y_test_df = y_test\n",
    "del y_test\n",
    "gc.collect()\n",
    "\n",
    "''' parameter\n",
    "'''\n",
    "params = {\n",
    "        \"objective\" : \"multiclass\", \n",
    "        \"metric\" : \"multi_error\", \n",
    "        'num_class':4,\n",
    "        \"num_leaves\" : 30, \n",
    "        \"learning_rate\" : 0.01, \n",
    "        \"bagging_fraction\" : 0.9,\n",
    "        \"bagging_seed\" : 0, \n",
    "        \"num_threads\" : 4,\n",
    "        \"colsample_bytree\" : 0.5,\n",
    "        'min_data_in_leaf':100, \n",
    "        'min_split_gain':0.00019\n",
    "}\n",
    "model = lgb.train(  params, \n",
    "                    train_set = train,\n",
    "                    num_boost_round=2000,\n",
    "                    early_stopping_rounds=200,\n",
    "                    verbose_eval=100, \n",
    "                    valid_sets=[train,train_test]\n",
    "                  )\n",
    "\n",
    "\n",
    "test = featureModify(False, None)\n",
    "print(\"Done test read\")\n",
    "df_sub = pd.DataFrame()\n",
    "df_sub['id'] = test['id']\n",
    "test = test.drop('id',axis=1)\n",
    "\n",
    "y_pred = model.predict(test, num_iteration=model.best_iteration)\n",
    "\n",
    "df_sub = pd.DataFrame(np.concatenate((np.arange(len(test))[:, np.newaxis], y_pred), axis=1), columns=['id', 'A', 'B', 'C', 'D'])\n",
    "df_sub['id'] = df_sub['id'].astype(int)\n",
    "\n",
    "print(df_sub)\n",
    "df_sub.to_csv(\"./submission/fatalities_submission3.csv\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
