{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge, LinearRegression\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.base import TransformerMixin, BaseEstimator\nimport re \nimport scipy\nfrom scipy import sparse\nimport gc \nfrom IPython.display import display, HTML\nfrom pprint import pprint\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npd.options.display.max_colwidth=300","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:26:26.541134Z","iopub.execute_input":"2022-04-22T05:26:26.541788Z","iopub.status.idle":"2022-04-22T05:26:27.581186Z","shell.execute_reply.started":"2022-04-22T05:26:26.541673Z","shell.execute_reply":"2022-04-22T05:26:27.58044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Start","metadata":{}},{"cell_type":"code","source":"def clean(data, col):\n    # Clean some punctutations\n    data[col] = data[col].str.replace('\\n', ' ')\n    data[col] = data[col].str.replace(r'([a-zA-Z]+)([/!?.])([a-zA-Z]+)',r'\\1 \\2 \\3')\n    # Replace repeating characters more than 3 times to length of 3\n    data[col] = data[col].str.replace(r'([*!?\\'])\\1\\1{2,}',r'\\1\\1\\1')    \n    # Add space around repeating characters\n    data[col] = data[col].str.replace(r'([*!?\\']+)',r' \\1 ')    \n    # patterns with repeating characters \n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1{2,}\\b',r'\\1\\1')\n    data[col] = data[col].str.replace(r'([a-zA-Z])\\1\\1{2,}\\B',r'\\1\\1\\1')\n    data[col] = data[col].str.replace(r'[ ]{2,}',' ').str.strip()   \n    \n    return data","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:26:59.502629Z","iopub.execute_input":"2022-04-22T05:26:59.503091Z","iopub.status.idle":"2022-04-22T05:26:59.516374Z","shell.execute_reply.started":"2022-04-22T05:26:59.503037Z","shell.execute_reply":"2022-04-22T05:26:59.512922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:06.613564Z","iopub.execute_input":"2022-04-22T05:27:06.613837Z","iopub.status.idle":"2022-04-22T05:27:08.290582Z","shell.execute_reply.started":"2022-04-22T05:27:06.61379Z","shell.execute_reply":"2022-04-22T05:27:08.289868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Give more weight to severe toxic \ndf['severe_toxic'] = df.severe_toxic * 2\ndf['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndf['y'] = df['y']/df['y'].max()\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:08.292054Z","iopub.execute_input":"2022-04-22T05:27:08.292312Z","iopub.status.idle":"2022-04-22T05:27:53.029862Z","shell.execute_reply.started":"2022-04-22T05:27:08.292275Z","shell.execute_reply":"2022-04-22T05:27:53.029092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 7\n\nfrac_1 = 0.7\nfrac_1_factor = 1.5\n\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n                        df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n                                            random_state = 10*(fld+1))], axis=0)\n    tmp_df.to_csv(f'/kaggle/working/df_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:53.033972Z","iopub.execute_input":"2022-04-22T05:27:53.034186Z","iopub.status.idle":"2022-04-22T05:27:56.394417Z","shell.execute_reply.started":"2022-04-22T05:27:53.034161Z","shell.execute_reply":"2022-04-22T05:27:56.392687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = clean(df,'text')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 7\n\nfrac_1 = 0.7\nfrac_1_factor = 1.5\n\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = pd.concat([df[df.y>0].sample(frac=frac_1, random_state = 10*(fld+1)) , \n                        df[df.y==0].sample(n=int(len(df[df.y>0])*frac_1*frac_1_factor) , \n                                            random_state = 10*(fld+1))], axis=0)\n    tmp_df.to_csv(f'/kaggle/working/df_clean_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df,tmp_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:56.395642Z","iopub.execute_input":"2022-04-22T05:27:56.395914Z","iopub.status.idle":"2022-04-22T05:27:56.519494Z","shell.execute_reply.started":"2022-04-22T05:27:56.395878Z","shell.execute_reply":"2022-04-22T05:27:56.518785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ruddit data","metadata":{}},{"cell_type":"code","source":"df_ = pd.read_csv(\"../input/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv\")\n\ndf_ = df_[['txt', 'offensiveness_score']].rename(columns={'txt': 'text',\n                                                                'offensiveness_score':'y'})\n\ndf_['y'] = (df_['y'] - df_.y.min()) / (df_.y.max() - df_.y.min()) \ndf_.y.hist()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:56.521688Z","iopub.execute_input":"2022-04-22T05:27:56.522195Z","iopub.status.idle":"2022-04-22T05:27:56.833416Z","shell.execute_reply.started":"2022-04-22T05:27:56.522158Z","shell.execute_reply":"2022-04-22T05:27:56.832681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create 3 versions of data","metadata":{}},{"cell_type":"code","source":"df_ = clean(df_,'text')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:56.834726Z","iopub.execute_input":"2022-04-22T05:27:56.834989Z","iopub.status.idle":"2022-04-22T05:27:57.544947Z","shell.execute_reply.started":"2022-04-22T05:27:56.834953Z","shell.execute_reply":"2022-04-22T05:27:57.544211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_folds = 7\nfrac_1 = 0.7\n\nfor fld in range(n_folds):\n    print(f'Fold: {fld}')\n    tmp_df = df_.sample(frac=frac_1, random_state = 10*(fld+1))\n    tmp_df.to_csv(f'/kaggle/working/df2_fld{fld}.csv', index=False)\n    print(tmp_df.shape)\n    print(tmp_df['y'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:57.546261Z","iopub.execute_input":"2022-04-22T05:27:57.546514Z","iopub.status.idle":"2022-04-22T05:27:57.884159Z","shell.execute_reply.started":"2022-04-22T05:27:57.546481Z","shell.execute_reply":"2022-04-22T05:27:57.882509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df_, tmp_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:57.885557Z","iopub.execute_input":"2022-04-22T05:27:57.885845Z","iopub.status.idle":"2022-04-22T05:27:57.991992Z","shell.execute_reply.started":"2022-04-22T05:27:57.885794Z","shell.execute_reply":"2022-04-22T05:27:57.991262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Validation and Test data  \n","metadata":{}},{"cell_type":"code","source":"# Validation data \n\ndf_val = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/validation_data.csv\")\ndf_val.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:57.993307Z","iopub.execute_input":"2022-04-22T05:27:57.993751Z","iopub.status.idle":"2022-04-22T05:27:58.517719Z","shell.execute_reply.started":"2022-04-22T05:27:57.993708Z","shell.execute_reply":"2022-04-22T05:27:58.517076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test data\n\ndf_sub = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ndf_sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:58.546345Z","iopub.execute_input":"2022-04-22T05:27:58.546601Z","iopub.status.idle":"2022-04-22T05:27:58.630482Z","shell.execute_reply.started":"2022-04-22T05:27:58.546564Z","shell.execute_reply":"2022-04-22T05:27:58.629759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Toxic data","metadata":{}},{"cell_type":"code","source":"val_preds_arr1 = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2 = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arr = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([(\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5)))])\n    pipeline = Pipeline([(\"features\", features), (\"clf\", Ridge())])        \n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    print(\"\\npredict validation data \")\n    val_preds_arr1[:,fld] = pipeline.predict(df_val['less_toxic'])\n    val_preds_arr2[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n    print(\"\\npredict test data \")\n    test_preds_arr[:,fld] = pipeline.predict(df_sub['text'])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:25:39.20176Z","iopub.execute_input":"2022-04-22T00:25:39.202622Z","iopub.status.idle":"2022-04-22T00:40:08.846845Z","shell.execute_reply.started":"2022-04-22T00:25:39.202581Z","shell.execute_reply":"2022-04-22T00:40:08.845934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Toxic __clean__ data","metadata":{}},{"cell_type":"code","source":"val_preds_arr1c = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2c = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arrc = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df_clean_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([(\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5)))])\n    pipeline = Pipeline([(\"features\", features), (\"clf\", Ridge())])        \n\n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    print(\"\\npredict validation data \")\n    val_preds_arr1c[:,fld] = pipeline.predict(df_val['less_toxic'])\n    val_preds_arr2c[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n    print(\"\\npredict test data \")\n    test_preds_arrc[:,fld] = pipeline.predict(df_sub['text'])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:27:58.646471Z","iopub.execute_input":"2022-04-22T05:27:58.646908Z","iopub.status.idle":"2022-04-22T05:37:12.481378Z","shell.execute_reply.started":"2022-04-22T05:27:58.646867Z","shell.execute_reply":"2022-04-22T05:37:12.480637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Ruddit data pipeline","metadata":{}},{"cell_type":"code","source":"val_preds_arr1_ = np.zeros((df_val.shape[0], n_folds))\nval_preds_arr2_ = np.zeros((df_val.shape[0], n_folds))\ntest_preds_arr_ = np.zeros((df_sub.shape[0], n_folds))\n\nfor fld in range(n_folds):\n    print(\"\\n\\n\")\n    print(f' ****************************** FOLD: {fld} ******************************')\n    df = pd.read_csv(f'/kaggle/working/df2_fld{fld}.csv')\n    print(df.shape)\n\n    features = FeatureUnion([(\"vect3\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5)))])       \n\n    pipeline = Pipeline([(\"features\", features), (\"clf\", Ridge())])          \n    \n    print(\"\\nTrain:\")\n    # Train the pipeline\n    pipeline.fit(df['text'], df['y'])\n    \n    # What are the important features for toxicity\n\n    print('\\nTotal number of features:', len(pipeline['features'].get_feature_names()) )\n\n    feature_wts = sorted(list(zip(pipeline['features'].get_feature_names(), \n                                  np.round(pipeline['clf'].coef_,2) )), \n                         key = lambda x:x[1], \n                         reverse=True)\n\n    pprint(feature_wts[:30])\n    \n    print(\"\\npredict validation data \")\n    val_preds_arr1_[:,fld] = pipeline.predict(df_val['less_toxic'])\n    val_preds_arr2_[:,fld] = pipeline.predict(df_val['more_toxic'])\n\n    print(\"\\npredict test data \")\n    test_preds_arr_[:,fld] = pipeline.predict(df_sub['text'])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:37:12.482576Z","iopub.execute_input":"2022-04-22T05:37:12.482838Z","iopub.status.idle":"2022-04-22T05:43:20.538831Z","shell.execute_reply.started":"2022-04-22T05:37:12.482788Z","shell.execute_reply":"2022-04-22T05:43:20.538058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del df, pipeline, feature_wts\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:43:20.541266Z","iopub.execute_input":"2022-04-22T05:43:20.541528Z","iopub.status.idle":"2022-04-22T05:43:20.663453Z","shell.execute_reply.started":"2022-04-22T05:43:20.54149Z","shell.execute_reply":"2022-04-22T05:43:20.662675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validate the pipeline ","metadata":{}},{"cell_type":"code","source":"print(\" Toxic data \")\np1 = val_preds_arr1.mean(axis=1)\np2 = val_preds_arr2.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p1 < p2).mean() * 100,2)}')\n\nprint(\" Ruddit data \")\np3 = val_preds_arr1_.mean(axis=1)\np4 = val_preds_arr2_.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p3 < p4).mean() * 100,2)}')\n\nprint(\" Toxic CLEAN data \")\np5 = val_preds_arr1c.mean(axis=1)\np6 = val_preds_arr2c.mean(axis=1)\n\nprint(f'Validation Accuracy is { np.round((p5 < p6).mean() * 100,2)}')\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:43:20.664606Z","iopub.execute_input":"2022-04-22T05:43:20.664877Z","iopub.status.idle":"2022-04-22T05:43:20.676013Z","shell.execute_reply.started":"2022-04-22T05:43:20.664841Z","shell.execute_reply":"2022-04-22T05:43:20.675004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# unclean X","metadata":{}},{"cell_type":"code","source":"print(\"Find best weight\") \n\nwts_acc = []\nfor i in range(30,70,1):\n    for j in range(0,20,1):\n        w1 = i/100\n        w2 = (100 - i - j)/100\n        w3 = (1 - w1 - w2 )\n        p1_wt = w1*p1 + w2*p3 + w3*p5\n        p2_wt = w1*p2 + w2*p4 + w3*p6\n        wts_acc.append( (w1,w2,w3, \n                         np.round((p1_wt < p2_wt).mean() * 100,2))\n                      )","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:54:47.832326Z","iopub.execute_input":"2022-04-22T00:54:47.83261Z","iopub.status.idle":"2022-04-22T00:54:48.0321Z","shell.execute_reply.started":"2022-04-22T00:54:47.832575Z","shell.execute_reply":"2022-04-22T00:54:48.031469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w1,w2,w3,_ = sorted(wts_acc, key=lambda x:x[3], reverse=True)[0]\nprint(w1, w2, w3)\np1_wt = w1*p1 + w2*p3 + w3*p5\np2_wt = w1*p2 + w2*p4 + w3*p6","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:54:48.033116Z","iopub.execute_input":"2022-04-22T00:54:48.033354Z","iopub.status.idle":"2022-04-22T00:54:48.038929Z","shell.execute_reply.started":"2022-04-22T00:54:48.033322Z","shell.execute_reply":"2022-04-22T00:54:48.038184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['p1'] = p1_wt\ndf_val['p2'] = p2_wt\ndf_val['diff'] = np.abs(p2_wt - p1_wt)\n\ndf_val['correct'] = (p1_wt < p2_wt).astype('int')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:43:20.716382Z","iopub.execute_input":"2022-04-22T05:43:20.716648Z","iopub.status.idle":"2022-04-22T05:43:20.724997Z","shell.execute_reply.started":"2022-04-22T05:43:20.716612Z","shell.execute_reply":"2022-04-22T05:43:20.724172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict on test data ","metadata":{}},{"cell_type":"code","source":"# Predict using pipeline\n\ndf_sub['score'] = w1*test_preds_arr.mean(axis=1) + w2*test_preds_arr_.mean(axis=1) + w3*test_preds_arrc.mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:54:48.098728Z","iopub.execute_input":"2022-04-22T00:54:48.099066Z","iopub.status.idle":"2022-04-22T00:54:48.1052Z","shell.execute_reply.started":"2022-04-22T00:54:48.099027Z","shell.execute_reply":"2022-04-22T00:54:48.104471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Bert Ensemble","metadata":{}},{"cell_type":"code","source":"%%time\n\nimport os\nimport gc\nimport cv2\nimport copy\nimport time\nimport random\n\n# For data manipulation\nimport numpy as np\nimport pandas as pd\n\n# Pytorch Imports\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\n# For Transformer Models\nfrom transformers import AutoTokenizer, AutoModel\n\n# Utils\nfrom tqdm import tqdm\n\n# For descriptive error messages\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n\nCONFIG = dict(\n    seed = 42,\n    model_name = '../input/roberta-base',\n    test_batch_size = 64,\n    max_length = 128,\n    num_classes = 1,\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n)\n\nCONFIG[\"tokenizer\"] = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n\nMODEL_PATHS = [\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-0.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-1.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-2.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-3.bin',\n    '../input/k/saurabhbagchi/pytorch-w-b-jigsaw-starter/Loss-Fold-4.bin'\n]\n\ndef set_seed(seed = 42):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    \n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \n    \nclass JigsawDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length):\n        self.df = df\n        self.max_len = max_length\n        self.tokenizer = tokenizer\n        self.text = df['text'].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        text = self.text[index]\n        inputs = self.tokenizer.encode_plus(\n                        text,\n                        truncation=True,\n                        add_special_tokens=True,\n                        max_length=self.max_len,\n                        padding='max_length'\n                    )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']        \n        \n        return {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long)\n        }    \n\n    \nclass JigsawModel(nn.Module):\n    def __init__(self, model_name):\n        super(JigsawModel, self).__init__()\n        self.model = AutoModel.from_pretrained(model_name)\n        self.drop = nn.Dropout(p=0.2)\n        self.fc = nn.Linear(768, CONFIG['num_classes'])\n        \n    def forward(self, ids, mask):        \n        out = self.model(input_ids=ids,attention_mask=mask,\n                         output_hidden_states=False)\n        out = self.drop(out[1])\n        outputs = self.fc(out)\n        return outputs\n    \n@torch.no_grad()\ndef valid_fn(model, dataloader, device):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, data in bar:\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        \n        outputs = model(ids, mask)\n        PREDS.append(outputs.view(-1).cpu().detach().numpy()) \n    \n    PREDS = np.concatenate(PREDS)\n    gc.collect()\n    \n    return PREDS\n\n\ndef inference(model_paths, dataloader, device):\n    final_preds = []\n    for i, path in enumerate(model_paths):\n        model = JigsawModel(CONFIG['model_name'])\n        model.to(CONFIG['device'])\n        model.load_state_dict(torch.load(path))\n        \n        print(f\"Getting predictions for model {i+1}\")\n        preds = valid_fn(model, dataloader, device)\n        final_preds.append(preds)\n    \n    final_preds = np.array(final_preds)\n    final_preds = np.mean(final_preds, axis=0)\n    return final_preds\n\n\nset_seed(CONFIG['seed'])\ndf = pd.read_csv(\"../input/jigsaw-toxic-severity-rating/comments_to_score.csv\")\ndf.head()\n\ntest_dataset = JigsawDataset(df, CONFIG['tokenizer'], max_length=CONFIG['max_length'])\ntest_loader = DataLoader(test_dataset, batch_size=CONFIG['test_batch_size'],\n                         num_workers=2, shuffle=False, pin_memory=True)\n\npreds1 = inference(MODEL_PATHS, test_loader, CONFIG['device'])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:43:20.822899Z","iopub.execute_input":"2022-04-22T05:43:20.82336Z","iopub.status.idle":"2022-04-22T05:46:47.567509Z","shell.execute_reply.started":"2022-04-22T05:43:20.823323Z","shell.execute_reply":"2022-04-22T05:46:47.566592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = (preds1-preds1.min())/(preds1.max()-preds1.min())","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:46:47.569067Z","iopub.execute_input":"2022-04-22T05:46:47.569546Z","iopub.status.idle":"2022-04-22T05:46:47.574764Z","shell.execute_reply.started":"2022-04-22T05:46:47.569503Z","shell.execute_reply":"2022-04-22T05:46:47.574023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub['score'] = df_sub['score']*0.85 + preds*0.15 ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:46:47.575875Z","iopub.execute_input":"2022-04-22T05:46:47.576129Z","iopub.status.idle":"2022-04-22T05:46:47.587409Z","shell.execute_reply.started":"2022-04-22T05:46:47.576095Z","shell.execute_reply":"2022-04-22T05:46:47.586679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T05:46:47.589022Z","iopub.execute_input":"2022-04-22T05:46:47.589398Z","iopub.status.idle":"2022-04-22T05:46:47.623435Z","shell.execute_reply.started":"2022-04-22T05:46:47.589326Z","shell.execute_reply":"2022-04-22T05:46:47.622697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}